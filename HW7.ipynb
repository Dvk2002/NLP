{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBOzASQpML49jOWPG3RHWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dvk2002/NLP/blob/main/HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPBBiLIgwvRD",
        "outputId": "4996a5a6-987d-4b76-9d37-029e6f654844"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1CrnrNfxIDC",
        "outputId": "312bf91a-bd91-49d1-cbb2-681d05f715f2"
      },
      "source": [
        "cd /gdrive/My Drive/Colab_Notebooks/NLP/L7"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab_Notebooks/NLP/L7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiNnYHfXxXFh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOle2rqsxmLe"
      },
      "source": [
        "data = pd.read_excel('отзывы за лето.xls')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jY_RX1Xpy3m_",
        "outputId": "586a7e91-732a-4e05-bda1-3fe838fb17a3"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>it just works</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>в целое удобноной приложениеиз минус хотеть сл...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Отлично все</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>отлично всё</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>стать зависать на 1 работа антивирус далёкий н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Очень удобно, работает быстро.</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>очень удобно работать быстро</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20654</th>\n",
              "      <td>1</td>\n",
              "      <td>Ну и шляпа,с роот правами бесполезная прога,ра...</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>ну и шляпас роот право бесполезный прогаразраб...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>5</td>\n",
              "      <td>Ок</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>около</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20656</th>\n",
              "      <td>4</td>\n",
              "      <td>Доволен</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>довольный</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20657</th>\n",
              "      <td>1</td>\n",
              "      <td>Песопаснасть, рут ни нужын</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>песопаснастя рута ни нужын</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20658</th>\n",
              "      <td>5</td>\n",
              "      <td>Сбербанк бомбовая компания на сегодняшний день...</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>сбербанк бомбовый компания на сегодняшний день...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19748 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Rating  ... target\n",
              "0           5  ...      1\n",
              "1           4  ...      1\n",
              "2           5  ...      1\n",
              "3           5  ...      1\n",
              "4           5  ...      1\n",
              "...       ...  ...    ...\n",
              "20654       1  ...      0\n",
              "20655       5  ...      1\n",
              "20656       4  ...      1\n",
              "20657       1  ...      0\n",
              "20658       5  ...      1\n",
              "\n",
              "[19748 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il8Vk_-kzi1y",
        "outputId": "90aa4859-ad57-47ef-e4b2-7bc7a43517e1"
      },
      "source": [
        "data.Rating.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    14586\n",
              "1     2276\n",
              "4     2138\n",
              "3      911\n",
              "2      748\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or5PRZKg3EzO",
        "outputId": "77442c54-b6e6-48a8-b611-8cb6939877a4"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ROndjG3IPn",
        "outputId": "1fba5607-15c2-4687-d91d-d5fb017989a3"
      },
      "source": [
        "pip install stop_words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=57474bac0f2ac396e4b18a7e64b741dbc11679ab51194e753b3c91d4fd294e68\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTsXUq4YsQke",
        "outputId": "3c5640ae-ce8f-4ea7-f496-9b78c4fbcc68"
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyLxgJZa53AC",
        "outputId": "f9c0efe4-744a-4704-913d-5d4b0f993a6b"
      },
      "source": [
        "pip install gensim --upgrade"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 93 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0WMIr74scor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54019208-eb80-47f6-9c07-457cc05d2068"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0sn9qRT_uSp"
      },
      "source": [
        "emb_mod=KeyedVectors.load('213/model.model' )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCX6M8xC4-Ww"
      },
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9AksjlH33iy"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "exclude = set(punctuation)\n",
        "sw = set(get_stop_words(\"ru\"))\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in exclude]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "data['text'] = data['Content'].apply(preprocess_text)\n",
        "data = data[data['Rating'] != 3]\n",
        "data['target'] = (data['Rating'] > 3)*1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_ieE_to84vrQ",
        "outputId": "a4302096-7973-4dc6-f2a7-494d72bbc081"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>it just works</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>в целое удобноной приложениеиз минус хотеть сл...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Отлично все</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>отлично всё</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>стать зависать на 1 работа антивирус далёкий н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Очень удобно, работает быстро.</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>очень удобно работать быстро</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ... target\n",
              "0       5  ...      1\n",
              "1       4  ...      1\n",
              "2       5  ...      1\n",
              "3       5  ...      1\n",
              "4       5  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kybjolgs7c1I"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU,Flatten\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Input, Bidirectional,Reshape, Activation, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8UDLzvkL5tB"
      },
      "source": [
        "from sklearn import model_selection, preprocessing\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data.text, data.target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YmgubWNNlMy"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "\n",
        "train_data = train_data.batch(2048)\n",
        "valid_data = valid_data.batch(2048)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niDA6WfJN1Sn"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks48VjP58JZP"
      },
      "source": [
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 30\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    # ngrams=(1, 5),\n",
        "    output_sequence_length=seq_len\n",
        "    )\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xroWrxwbEQl"
      },
      "source": [
        "weights=emb_mod[vectorize_layer.get_vocabulary()]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x-p5xB33fPD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLF2YSod5Uhj"
      },
      "source": [
        "Загружаем веса и не обучаем их"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMUvRaiK_Ntp"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(len(vectorize_layer.get_vocabulary()), 300,weights=[weights],trainable=False, mask_zero=True),\n",
        "  Conv1D(512, 3),\n",
        "  Activation(\"relu\"),\n",
        "  GlobalMaxPooling1D(),\n",
        "  # Dropout(0.2),\n",
        "  Dense(300, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(50, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(10, activation='relu'),\n",
        "  # tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\n",
        "  ])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2OfVBxxPGcl",
        "outputId": "8ce5bfa3-617c-477b-849a-e8d8d02c9919"
      },
      "source": [
        "model.compile(optimizer='adam',         \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data, validation_data=valid_data, epochs=10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.4296 - accuracy: 0.8471 - val_loss: 0.2566 - val_accuracy: 0.8459\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2335 - accuracy: 0.8501 - val_loss: 0.2407 - val_accuracy: 0.8961\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2136 - accuracy: 0.8821 - val_loss: 0.2225 - val_accuracy: 0.9084\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1970 - accuracy: 0.9068 - val_loss: 0.2124 - val_accuracy: 0.9137\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1830 - accuracy: 0.9151 - val_loss: 0.2060 - val_accuracy: 0.9176\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1691 - accuracy: 0.9251 - val_loss: 0.2061 - val_accuracy: 0.9180\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1580 - accuracy: 0.9305 - val_loss: 0.2009 - val_accuracy: 0.9236\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.1420 - accuracy: 0.9404 - val_loss: 0.2085 - val_accuracy: 0.9210\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1284 - accuracy: 0.9498 - val_loss: 0.2232 - val_accuracy: 0.9178\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1172 - accuracy: 0.9549 - val_loss: 0.2283 - val_accuracy: 0.9184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3692fdcbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfg27Wpt3dOc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqacx9Gx5fjN"
      },
      "source": [
        "Загружаем веса и обучаем их"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX1Zf1IEqB2h"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(len(vectorize_layer.get_vocabulary()), 300,weights=[weights],trainable=True, mask_zero=True))\n",
        "model.add(Conv1D(512, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VadbfLDuGff",
        "outputId": "52ea76c2-0d6a-4955-8128-77909f62a231"
      },
      "source": [
        "model.compile(optimizer='adam',         \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data, validation_data=valid_data, epochs=10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.4407 - accuracy: 0.8422 - val_loss: 0.2393 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2201 - accuracy: 0.8957 - val_loss: 0.2192 - val_accuracy: 0.9012\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1928 - accuracy: 0.9137 - val_loss: 0.2005 - val_accuracy: 0.9174\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1672 - accuracy: 0.9299 - val_loss: 0.1917 - val_accuracy: 0.9228\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1440 - accuracy: 0.9408 - val_loss: 0.1896 - val_accuracy: 0.9251\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1244 - accuracy: 0.9511 - val_loss: 0.1926 - val_accuracy: 0.9273\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1070 - accuracy: 0.9621 - val_loss: 0.1863 - val_accuracy: 0.9273\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0873 - accuracy: 0.9693 - val_loss: 0.1964 - val_accuracy: 0.9279\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0672 - accuracy: 0.9786 - val_loss: 0.3226 - val_accuracy: 0.8991\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0976 - accuracy: 0.9596 - val_loss: 0.2114 - val_accuracy: 0.9192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3692f45250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTz2I4qW3M3g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a22jjhaf5m87"
      },
      "source": [
        "Обучаем веса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kvhUQ_cr7bq"
      },
      "source": [
        "class model_w(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(model_w, self).__init__()\n",
        "        self.vec = vectorize_layer\n",
        "        self.emb = Embedding(len(vectorize_layer.get_vocabulary()), 300, mask_zero=True)\n",
        "        self.act=Activation(\"relu\")\n",
        "        self.norm=LayerNormalization()\n",
        "        self.conv=Conv1D(512, 3)\n",
        "        self.pool = GlobalMaxPooling1D()\n",
        "        self.drop=Dropout(0.2)     \n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.fc2 = Dense(10, activation='relu')\n",
        "        self.fc3 = Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        x = self.vec(x)\n",
        "        emb = self.emb(x)\n",
        "        x= self.conv(emb)\n",
        "        x=self.act(x)\n",
        "        pool_x = self.pool(x)       \n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.fc2(self.drop(fc_x))\n",
        "        out = self.fc3(self.drop(fc_x))\n",
        "\n",
        "        return out"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf47hfHjuDS0",
        "outputId": "38509d94-cbcb-4971-bd3d-b59c7326017b"
      },
      "source": [
        "model=model_w()\n",
        "model.compile(optimizer='nadam',         \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data, validation_data=valid_data, epochs=10)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 40s 5s/step - loss: 0.5374 - accuracy: 0.7638 - val_loss: 0.3680 - val_accuracy: 0.8459\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3551 - accuracy: 0.8471 - val_loss: 0.2703 - val_accuracy: 0.8459\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.2632 - accuracy: 0.8485 - val_loss: 0.2141 - val_accuracy: 0.8459\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.2032 - accuracy: 0.8963 - val_loss: 0.1800 - val_accuracy: 0.9263\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1525 - accuracy: 0.9454 - val_loss: 0.1850 - val_accuracy: 0.9287\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1256 - accuracy: 0.9547 - val_loss: 0.2102 - val_accuracy: 0.9212\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.1018 - accuracy: 0.9655 - val_loss: 0.2004 - val_accuracy: 0.9234\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0945 - accuracy: 0.9669 - val_loss: 0.2346 - val_accuracy: 0.9238\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.2343 - val_accuracy: 0.9247\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 0.2757 - val_accuracy: 0.9204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3693597e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzVu5_-kC_PF"
      },
      "source": [
        "Значимой разницы не наблюдается. Модель быстро переобучается, нужно выбирать оптимальное количество эпох или увеличивать регуляризацию."
      ]
    }
  ]
}